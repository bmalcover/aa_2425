{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Segmentació\n",
    "\n",
    "Fins ara tant a teoria com a les anteriors sessions de pràctiques hem vist com emprar models de segmentació i detecció amb *datasets* ja preparats. Però com feim la tasca de crear les màscares pel *ground truth* és una tasca que no hem vist fins ara. A la sessió d'aquesta setmana combinarem aquesta feina amb l'ús de la xarxa YOLO, emprant les versions d'[Ultralytics](https://docs.ultralytics.com/)\n",
    "\n",
    "En aquesta pràctica, aprendrem a utilitzar [*Label Studio*](https://labelstud.io/guide), una eina versàtil i de codi obert que facilita l'etiquetatge de dades per a projectes d'aprenentatge automàtic. L'objectiu principal serà comprendre com podem generar ground truth (GT) per a tasques de segmentació i detecció d'objectes, un pas crític per entrenar models precisos i robustos.\n",
    "\n",
    "Durant la sessió:\n",
    "\n",
    "1. Definirem etiquetes i esquemes: Establirem les categories d'objectes i regles per a la segmentació o detecció.\n",
    "2. Practicarem amb etiquetatge manual: Crearem etiquetes manualment, identificant regions o delimitant objectes dins d'un conjunt d'imatges.\n",
    "3. Exportarem les etiquetes generades: Coneixerem com exportar el ground truth en formats compatibles amb llibreries com ``PyTorch`` o ``Ultralythics``.\n",
    "\n",
    "Aquesta pràctica ens ajudarà a entendre millor el procés d'etiquetatge i a generar dades de qualitat per a experiments en segmentació semàntica o detecció d'objectes.\n",
    "\n",
    "**NOTA:** Farem la generació del GT en local\n",
    "\n",
    "## *Label Studio*.\n",
    "\n",
    "**Instal·lació**\n",
    "\n",
    "```\n",
    "pip install label-studio\n",
    "```\n",
    "\n",
    "**Execució**\n",
    "\n",
    "```\n",
    "label-studio start\n",
    "```\n",
    "\n",
    "Una vegada iniciat haureu de crear un compte de l'aplicació.\n",
    "\n",
    "**GUI**\n",
    "\n",
    "![](screen.png)\n",
    "\n",
    "\n",
    "**Ens hi posam**\n",
    "\n",
    "**NOTA**:\n",
    "\n",
    "\n",
    "| Info            | Enllaços                                                                     |\n",
    "|-----------------|------------------------------------------------------------------------------|\n",
    "| Codi per classe | [Enllaç](https://gist.github.com/rcland12/dc48e1963268ff98c8b2c4543e7a9be8)  |\n",
    "| Format COCO8    | [Enllaç](https://docs.ultralytics.com/es/datasets/detect/coco8/#introduction) |\n",
    "\n",
    "\n",
    "## Segmentació\n",
    "\n",
    "Emprarem exhaustivament la llibreria d'Ultralytics. Per instal·lar-la:\n",
    "\n",
    "```\n",
    "pip install ultralytics\n",
    "```\n",
    "\n",
    "Una vega obtenim el conjunt de dades podem emprar-ho per fer dues tasques diferents: predicció i entrenament. En ambdues tasques l'ús de mètriques és fonamental, ja sigui per emprar-ho com a funció de pèrdua o bé com a mesura de qualitat.\n",
    "\n",
    "A part de les mètriques que ja coneixeu (IOU i Dice coefficient per segmentació) existeix una funció àmpliament emprada per mesurar la qualitat d'aquest tipus de models: la **mAP**. Tot seguit teniu una explicació generada per ChatGPT i revisada per un humà:\n",
    "\n",
    "La mAP (mean Average Precision) és una mètrica àmpliament utilitzada per avaluar el rendiment en tasques de segmentació, especialment en problemes on cal detectar i delimitar objectes dins d'una imatge. Aquesta mètrica combina la precisió i la recuperació per calcular l'eficiència del model a l'hora de predir regions segmentades correctament.\n",
    "\n",
    "En segmentació, la mAP es calcula com la mitjana de les AP (Average Precision) per a diferents classes o nivells de superposició. Per a una sola classe, l'AP es deriva d'una corba de precisió-recall: es mesura la precisió mitjana en diferents llindars de confiança o de superposició, com l'IoU (Intersection over Union). L'IoU quantifica la superposició entre la màscara predita i la màscara real. Llindars comuns són 0.5 (coincidència moderada) o valors més alts per coincidències més estrictes.\n",
    "\n",
    "A la pràctica, la mAP per segmentació sol incloure aquests passos:\n",
    "\n",
    "- Calcul de l'IoU entre màscares predites i màscares reals.\n",
    "- Associar prediccions correctes a les reals segons un llindar d'IoU establert.\n",
    "- Generar la corba de precisió-recall.\n",
    "- Obtenir l'AP per classe i, finalment, la mitjana de totes les classes per obtenir la mAP.\n",
    "\n",
    "\n",
    "Una implementació de mAP extreta d'aquest [repositori](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/object_detection/metrics/mean_avg_precision.py)"
   ],
   "id": "ec13b7f0de0e642e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T12:07:22.486572Z",
     "start_time": "2024-12-05T12:07:22.433015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "epsilon = 1e-9\n",
    "\n",
    "def intersection_over_union(outputs, labels):\n",
    "    outputs = outputs.squeeze(1)  # B x 1 x H x W => B x H x W\n",
    "\n",
    "    intersection = (outputs & labels).float().sum((1, 2))\n",
    "    union = (outputs | labels).float().sum((1, 2))\n",
    "\n",
    "    iou = (intersection + epsilon) / (union + epsilon)\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def mean_average_precision(\n",
    "        pred_boxes, true_boxes, iou_threshold=0.5, num_classes=20\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates mean average precision\n",
    "\n",
    "    Parameters:\n",
    "        pred_boxes (list): list of lists containing all bboxes with each bboxes\n",
    "        specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n",
    "        true_boxes (list): Similar as pred_boxes except all the correct ones\n",
    "        iou_threshold (float): threshold where predicted bboxes is correct\n",
    "        num_classes (int): number of classes\n",
    "\n",
    "    Returns:\n",
    "        float: mAP value across all classes given a specific IoU threshold\n",
    "    \"\"\"\n",
    "\n",
    "    # list storing all AP for respective classes\n",
    "    average_precisions = []\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "\n",
    "        # Go through all predictions and targets,\n",
    "        # and only add the ones that belong to the\n",
    "        # current class c\n",
    "        for detection in pred_boxes:\n",
    "            if detection[1] == c:\n",
    "                detections.append(detection)\n",
    "\n",
    "        for true_box in true_boxes:\n",
    "            if true_box[1] == c:\n",
    "                ground_truths.append(true_box)\n",
    "\n",
    "        # find the amount of bboxes for each training example\n",
    "        # Counter here finds how many ground truth bboxes we get\n",
    "        # for each training example, so let's say img 0 has 3,\n",
    "        # img 1 has 5 then we will obtain a dictionary with:\n",
    "        # amount_bboxes = {0:3, 1:5}\n",
    "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "\n",
    "        # We then go through each key, val in this dictionary\n",
    "        # and convert to the following (w.r.t same example):\n",
    "        # ammount_bboxes = {0:torch.tensor[0,0,0], 1:torch.tensor[0,0,0,0,0]}\n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "        # sort by box probabilities which is index 2\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros((len(detections)))\n",
    "        FP = torch.zeros((len(detections)))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "\n",
    "        # If none exists for this class then we can safely skip\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            # Only take out the ground_truths that have the same\n",
    "            # training idx as detection\n",
    "            ground_truth_img = [\n",
    "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
    "            ]\n",
    "\n",
    "            best_iou = 0\n",
    "            best_gt_idx = 0\n",
    "\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                iou = intersection_over_union(\n",
    "                    torch.tensor(detection[3:]),\n",
    "                    torch.tensor(gt[3:]),\n",
    "                )\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "\n",
    "            if best_iou > iou_threshold:\n",
    "                # only detect ground truth detection once\n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "                    # true positive and add this bounding box to seen\n",
    "                    TP[detection_idx] = 1\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "\n",
    "            # if IOU is lower then the detection is a false positive\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "\n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "        # torch.trapz for numerical integration\n",
    "        average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "    return sum(average_precisions) / len(average_precisions)"
   ],
   "id": "bb6e17a93073bc58",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tasques a fer (si hi ha temps)\n",
    "\n",
    "1. Descarregar el conjunt de dades de [Cans Vs Moixos](https://www.kaggle.com/c/dogs-vs-cats/overview) de Kaggle i segmenta una part d'aquestes imatges.\n",
    "2. Fer inferència emprant [YOLOv5](https://docs.ultralytics.com/modes/predict/#key-features-of-predict-mode).\n",
    "3. Obté l'*mAP* de les imatges.\n",
    "4. Fer un procés de *fine-tunning* emprant [YOLOv5](https://docs.ultralytics.com/modes/train/) amb les dades emprades.\n",
    "5. Obté l'*mAP* de les imatges.\n",
    "\n"
   ],
   "id": "d43d6503b2bba0dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
