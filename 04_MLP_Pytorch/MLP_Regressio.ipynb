{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:29:39.554264Z",
     "start_time": "2024-10-15T13:29:33.328029Z"
    }
   },
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_friedman1"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introducció\n",
    "\n",
    "Avui començarem a fer feina amb **Pytorch**, ja que la segona part del curs tracta de xarxes neuronals profundes. Aquesta és una biblioteca de programari de codi obert dins l'àmbit d'aprenentatge automàtic, esta escrita en _Python_, _C++_ i _CUDA_, i basada en la biblioteca del programari _Torch_ del llenguatge _LUA_. **PyTorch** va ser desenvolupada inicialment pel departament d'intel·ligència artificial de l'empresa Facebook i l'empresa Uber.\n",
    "\n",
    "Començarem a conèixer aquesta llibreria mitjançant l'execució d'un exemple. \n",
    "\n",
    "## Generació de les dades\n",
    "Per fer aquest tutorial emprarem un conjunt de dades que s'autogenera a partir de certs paràmetres, la variable a predir es correspon amb la següent fórmula:\n",
    "\n",
    "$y(X) = 10 * \\sin(\\pi * X[0] * X[1]) + 20 * (X[2] - 0.5)^2 + 10 * X[3] + 5 * X[4] + noise * N(0, 1).$\n",
    "\n",
    "Com podeu observar en la fórmula anterior, tenim 5 variables útils, a més nosaltres en generarem 5 més per dificultar una mica el problema. Ens trobem davant un problema de regressió en el que haurem d'aconseguir que la xarxa aprengui a predir els valors de $y$ a partir dels 10 valors que es corresponen amb una observació.\n",
    "\n",
    "[Més informació](https://projecteuclid.org/journals/annals-of-statistics/volume-19/issue-1/Multivariate-Adaptive-Regression-Splines/10.1214/aos/1176347963.full)\n",
    "\n",
    "Si executau el codi següent obtindreu el conjunt de dades amb els dos conjunts que empram per entrenar:"
   ],
   "id": "264131be7418d8ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:25:17.524595Z",
     "start_time": "2024-10-15T14:25:17.502546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = make_friedman1(n_samples=2000, n_features=10, noise=0.0, random_state=33)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32) # ho passam al tipus de dades de Pytorch\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33,shuffle=True)\n"
   ],
   "id": "176b4f5c7205b083",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Definició de la xarxa\n",
    "\n",
    "El mòdul [torch.nn](https://pytorch.org/docs/stable/nn.html) conté els blocs basics per la construcció de les xarxes. Utilitzarem el contenidor `nn.Sequential` per definir el nostre model com una seqüència de capes que s'executen una rere l'altre. Recordeu que una xarxa no és més que un graf dirigit acíclic.\n",
    " \n",
    "Aquest és un mòdul que conté altres mòduls i els aplica en seqüència per produir una sortida. El mòdul lineal `nn.Linear` calcula la sortida de l'entrada mitjançant una funció lineal i opera els tensors interns pel seu pes i biaix. La capa ``nn.Flatten`` \"aplana\" la sortida de la capa lineal a un tensor 1D, perquè coincideixi amb la dimensionalitat que necessitem a la sortida.\n",
    "\n",
    "A més de la xarxa també definirem els paràmetres de l'entrenament. En aquest cas:\n",
    "\n",
    "- **Funció de pèrdua**: És la funció que volem minimitzar mitjançant l'entrenament. En aquest cas emprarem el error quadratic mitjà (MSE):$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2, $ on $y_i$ són els valors reals, $\\hat{y}_i$ són els valors predits i $n$ el nombre de mostres.\n",
    "- **Rati d'aprenentatge** (_Learning Rate_): Representa la velocitat o el pas amb el qual un model d'aprenentatge automàtic ajusta els pesos i els paràmetres durant el procés d'entrenament. És equivalent al paràmetre `eta` del perceptró.\n",
    "- **Algorisme d'Optimització**: Tècnica que s'empra per ajustar els pesos i paràmetres d'un model durant el procés d'entrenament. El seu objectiu principal és minimitzar la funció de pèrdua del model. Els optimitzadors determinen com s‟actualitzen els paràmetres del model en funció de l'error calculat (és dependent de la funció de pèrdua elegida). Nosaltres usarem [ADAM](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) per ser l'algorisme més emprat en l'actualitat. "
   ],
   "id": "edd70e85324d2cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 8,
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(10, 1)) #Hem definit un perceptró\n",
    "\n",
    "loss_fn = torch.nn.MSELoss() \n",
    "\n",
    "learning_rate =  1e-3 # Hiperparàmetre\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "968f327feed4bfa9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Entrenament\n",
    "\n",
    "Amb **Pytorch** hem de definir el nostre propi bucle d'entrenament, en el qual haurem de realitzar totes les passes d'una iteració:\n",
    "\n",
    "1. Predicció\n",
    "2. Càlcul del valor de la pèrdua\n",
    "3. Còmput del gradient respecte als paràmetres del model.\n",
    "4. Actualització dels pesos del model"
   ],
   "id": "82a278d92e4669cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "iter = 500  #nombre d'iteracions de l'entrenament\n",
    "loss_p = np.zeros(iter)  # guardam la pèrdua de cada iteració\n",
    "\n",
    "for t in range(iter):\n",
    "    # 1. PREDICCIÓ\n",
    "    # Passat endavant: calcula la y, fa la predicció passant x al model. \n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    #print(y_pred.shape)\n",
    "    # 2. CALCUL DE LA PÈRDUA\n",
    "    # Computa la pèrdua: l'error de predicció vs el valor correcte\n",
    "    # Es guarda la pèrdua en un array per futures visualitzacions\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss_p[t] = loss.item()\n",
    "    \n",
    "    #3. GRADIENT\n",
    "    # Posa a 0 els gradients del model per poder fer la passa enrere\n",
    "    model.zero_grad()\n",
    "\n",
    "   # Passa enrere: calcula el gradient de la pèrdua respecte a tots els paràmetres del model. \n",
    "   # Internament, s'emmagatzemen els paràmetres de cada mòdul a Tensors amb el paràmetere requires_grad=True, d\n",
    "   # de manera que aquesta crida calcularà gradients per tots els paràmetres del model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Actualitza els pesos utilitzant l'algorisme d'actualització\n",
    "    #4. OPTIMITZACIO\n",
    "    with torch.no_grad():\n",
    "        optimizer.step()\n",
    "\n",
    "# Mostram resultats\n",
    "plt.title(\"Funció de pèrdua (MSE) a cada iteració\")\n",
    "plt.plot(loss_p, label=\"train\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "e35a4a6f672e84e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### TODO\n",
    "\n",
    "Si pensam una mica, la funció que estam minimitzant durant l'entrenament és justament la mètrica que empraríem per avaluar la nostra xarxa amb el conjunt de test.\n",
    " \n",
    "Es demana que incorporeu l'avaluació del conjunt de test en el bucle anterior i mostreu el valor final per pantalla."
   ],
   "id": "e979349973f72db2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
